#!/usr/bin/env python3
"""
è½»é‡çº§VLMå¤„ç†å™¨ - ä¸ä¾èµ–å¤§æ¨¡å‹
ä½¿ç”¨OpenCVå’Œè§„åˆ™å¼•æ“å®ç°åŸºæœ¬è§†è§‰åŠŸèƒ½
"""

import numpy as np
import cv2
import time
from typing import Dict, List

class LightweightVLM:
    def __init__(self):
        self.color_ranges = {
            'red': ([0, 100, 100], [10, 255, 255]),
            'blue': ([110, 100, 100], [130, 255, 255]),
            'green': ([50, 100, 100], [70, 255, 255])
        }
    
    def process_instruction(self, image: np.ndarray, instruction: str) -> Dict:
        """å¤„ç†å›¾åƒå’ŒæŒ‡ä»¤"""
        start_time = time.time()
        
        # è§£ææŒ‡ä»¤
        color = self._extract_color(instruction)
        
        # æ£€æµ‹ç‰©ä½“
        objects = self._detect_objects(image, color)
        
        # é€‰æ‹©ç›®æ ‡ç‰©ä½“
        target = objects[0] if objects else self._get_default_object()
        
        # è®¡ç®—ä¸–ç•Œåæ ‡
        world_pos = self._pixel_to_world(target['center'])
        
        result = {
            "object_type": target['type'],
            "position": target['center'],
            "world_position": world_pos,
            "confidence": target['confidence'],
            "processing_time": time.time() - start_time
        }
        
        return result
    
    def _extract_color(self, instruction: str) -> str:
        """ä»æŒ‡ä»¤ä¸­æå–é¢œè‰²"""
        instruction_lower = instruction.lower()
        if "çº¢è‰²" in instruction or "red" in instruction_lower:
            return "red"
        elif "è“è‰²" in instruction or "blue" in instruction_lower:
            return "blue"
        elif "ç»¿è‰²" in instruction or "green" in instruction_lower:
            return "green"
        return None
    
    def _detect_objects(self, image: np.ndarray, target_color: str = None) -> List[Dict]:
        """æ£€æµ‹å›¾åƒä¸­çš„ç‰©ä½“"""
        objects = []
        hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
        
        colors_to_check = [target_color] if target_color else self.color_ranges.keys()
        
        for color_name in colors_to_check:
            if color_name not in self.color_ranges:
                continue
                
            lower, upper = self.color_ranges[color_name]
            mask = cv2.inRange(hsv, np.array(lower), np.array(upper))
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for contour in contours:
                if cv2.contourArea(contour) < 1000:
                    continue
                    
                x, y, w, h = cv2.boundingRect(contour)
                center = [x + w//2, y + h//2]
                area = cv2.contourArea(contour)
                confidence = min(area / 10000, 0.9)
                
                objects.append({
                    "type": f"{color_name}_object",
                    "center": center,
                    "bbox": [x, y, x+w, y+h],
                    "confidence": confidence,
                    "color": color_name
                })
        
        return objects
    
    def _pixel_to_world(self, pixel_pos: List[int]) -> List[float]:
        """åƒç´ åæ ‡è½¬ä¸–ç•Œåæ ‡"""
        px, py = pixel_pos
        # ç¡®ä¿åæ ‡åœ¨åˆç†èŒƒå›´å†…
        px = max(0, min(px, 640))
        py = max(0, min(py, 480))
        
        # å½’ä¸€åŒ–åˆ°[-1, 1]èŒƒå›´
        rel_x = (px - 320) / 320
        rel_y = (py - 240) / 240
        
        # æ˜ å°„åˆ°ä¸–ç•Œåæ ‡èŒƒå›´
        world_x = 0.5 + rel_x * 0.3  # é™åˆ¶åœ¨[0.2, 0.8]èŒƒå›´
        world_y = 0.0 + rel_y * 0.3  # é™åˆ¶åœ¨[-0.3, 0.3]èŒƒå›´
        world_z = 0.3
        
        # ç¡®ä¿ä¸–ç•Œåæ ‡åœ¨åˆç†èŒƒå›´å†…
        world_x = max(0.2, min(world_x, 0.8))
        world_y = max(-0.3, min(world_y, 0.3))
        
        return [world_x, world_y, world_z]
    
    def _get_default_object(self) -> Dict:
        """è·å–é»˜è®¤ç‰©ä½“"""
        return {
            "type": "unknown_object",
            "center": [320, 240],
            "confidence": 0.5,
            "color": "unknown"
        }

# æµ‹è¯•å‡½æ•°
def test_lightweight_vlm():
    """æµ‹è¯•è½»é‡çº§VLM"""
    print("ğŸ” æµ‹è¯•è½»é‡çº§VLM...")
    
    vlm = LightweightVLM()
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_image = np.zeros((480, 640, 3), dtype=np.uint8)
    test_image[200:280, 300:380] = [255, 0, 0]  # çº¢è‰²æ–¹å—
    
    # æµ‹è¯•æŒ‡ä»¤
    instruction = "è¯·è¯†åˆ«å›¾åƒä¸­çš„çº¢è‰²ç«‹æ–¹ä½“"
    
    # å¤„ç†
    result = vlm.process_instruction(test_image, instruction)
    
    print(f"âœ… è½»é‡çº§VLMæµ‹è¯•æˆåŠŸ")
    print(f"   æ£€æµ‹ç»“æœ: {result['object_type']}")
    print(f"   ç½®ä¿¡åº¦: {result['confidence']:.2f}")
    print(f"   ä¸–ç•Œåæ ‡: {result['world_position']}")
    print(f"   å¤„ç†æ—¶é—´: {result['processing_time']:.3f}ç§’")
    
    return result

if __name__ == "__main__":
    test_lightweight_vlm()
